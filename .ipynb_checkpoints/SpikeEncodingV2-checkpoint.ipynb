{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_sine_wave(a, f, phi, sigma, time):\n",
    "    mySin  = np.vectorize(math.sin)\n",
    "    return a*mySin(2*math.pi*f*time + phi*np.ones(len(time))) + np.random.rand(len(time))*sigma\n",
    "\n",
    "\n",
    "def sum_of_sine_waves(a, f, phi, sigma, time):\n",
    "    signal = np.zeros(len(time))\n",
    "    for j in range(len(a)):\n",
    "        signal = signal + noisy_sine_wave(a[j], f[j], phi[j], sigma, time)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def noisy_gaussian_wave(a, m, s, sigma, time):\n",
    "    return a*norm.pdf(time, m, s) + sigma*np.random.rand(len(time))\n",
    "\n",
    "\n",
    "def sum_of_gaussian_wave(a, m, s, sigma, time):\n",
    "    signal = np.zeros(len(time))\n",
    "    for j in range(len(a)):\n",
    "        signal = signal + noisy_gaussian_wave(a[j], m[j], s[j], 0, time) + np.random.rand(len(time))*sigma\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_contrast_encoder(data, factor):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Sengupta et al. (2017)\n",
    "    #   Petro et al. (2020)\n",
    "    diff = np.zeros(len(data)-1)\n",
    "    spikes = np.zeros(len(data))\n",
    "    for i in range(len(data)-1):\n",
    "        diff[i] = data[i+1] - data[i]\n",
    "    threshold = np.mean(diff) + factor * np.std(diff)\n",
    "    diff = np.insert(diff, 0, diff[1])\n",
    "    for i in range(len(data)):\n",
    "        if diff[i] > threshold:\n",
    "            spikes[i] = 1\n",
    "        elif diff[i] < -threshold:\n",
    "            spikes[i] = -1\n",
    "    return spikes, threshold\n",
    "\n",
    "\n",
    "def step_forward_encoder(data, threshold):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Petro et al. (2020)\n",
    "    startpoint = data[0]\n",
    "    spikes = np.zeros(len(data))\n",
    "    base = startpoint\n",
    "    for i in range(1,len(data)):\n",
    "        if data[i] > base + threshold:\n",
    "            spikes[i] = 1\n",
    "            base = base + threshold\n",
    "        elif data[i] < base - threshold:\n",
    "            spikes[i] = -1\n",
    "            base = base - threshold\n",
    "    return spikes, startpoint\n",
    "\n",
    "\n",
    "def moving_window_encoder(data, threshold, window):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Petro et al. (2020)\n",
    "    startpoint = data[0]\n",
    "    spikes = np.zeros(len(data))\n",
    "    base = np.mean(data[0:window+1])\n",
    "    for i in range(window+1):\n",
    "        if data[i] > base + threshold:\n",
    "            spikes[i] = 1\n",
    "        elif data[i] < base - threshold:\n",
    "            spikes[i] = -1\n",
    "    for i in range(window+2, len(data)):\n",
    "        base = np.mean(data[(i-window-1):(i-1)])\n",
    "        if data[i] > base + threshold:\n",
    "            spikes[i] = 1\n",
    "        elif data[i] < base - threshold:\n",
    "            spikes[i] = -1\n",
    "    return spikes, startpoint\n",
    "\n",
    "\n",
    "def hough_spike_encoder(data, fir):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Schrauwen et al. (2003)\n",
    "    spikes = np.zeros(len(data))\n",
    "    shift = min(data)\n",
    "    data = data - shift*np.ones(len(data))\n",
    "    for i in range(len(data)):\n",
    "        count = 0\n",
    "        for j in range(len(fir)):\n",
    "            if i+j < len(data):\n",
    "                if data[i+j] >= fir[j]:\n",
    "                    count = count + 1\n",
    "        if count == len(fir):\n",
    "            spikes[i] = 1\n",
    "            for j in range(len(fir)):\n",
    "                if i+j < len(data):\n",
    "                    data[i+j] = data[i+j] - fir[j]\n",
    "    return spikes, shift\n",
    "\n",
    "\n",
    "def modified_hough_spike_encoder(data, fir, threshold):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Schrauwen et al. (2003)\n",
    "    spikes = np.zeros(len(data))\n",
    "    shift = min(data)\n",
    "    data = data - shift*np.ones(len(data))\n",
    "    for i in range(len(data)):\n",
    "        error = 0\n",
    "        for j in range(len(fir)):\n",
    "            if i+j < len(data):\n",
    "                if data[i+j] < fir[j]:\n",
    "                    error = error + fir[j] - data[i+j]\n",
    "        if error <= threshold:\n",
    "            spikes[i] = 1\n",
    "            for j in range(len(fir)):\n",
    "                if i+j < len(data):\n",
    "                    data[i+j] = data[i+j] - fir[j]\n",
    "    return spikes, shift\n",
    "\n",
    "\n",
    "def ben_spike_encoder(data, fir, threshold):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Petro et al. (2020)\n",
    "    #   Sengupta et al. (2017)\n",
    "    #   Schrauwen et al. (2003)\n",
    "    spikes = np.zeros(len(data))\n",
    "    shift = min(data)\n",
    "    data = data - shift*np.ones(len(data))\n",
    "    for i in range(len(data)-len(fir)+1):\n",
    "        err1 = 0\n",
    "        err2 = 0\n",
    "        for j in range(len(fir)):\n",
    "            err1 = err1 + abs(data[i+j] - fir[j])\n",
    "            err2 = err2 + abs(data[i+j-1])\n",
    "        if err1 <= err2*threshold:\n",
    "            spikes[i] = 1\n",
    "            for j in range(len(fir)):\n",
    "                if i+j+1 < len(data):\n",
    "                    data[i+j+1] = data[i+j+1] - fir[j]\n",
    "    return spikes, shift\n",
    "\n",
    "\n",
    "def grf_spike_encoder(data, m, min_input, max_input):\n",
    "    # Adapted from algorithm provided in:\n",
    "    #   Bohté et al. (2002)\n",
    "    # Modifications: definition of sigma, removal of beta constant,\n",
    "    #                and modified WTA process\n",
    "\n",
    "    if np.isscalar(data):\n",
    "        data = [data]\n",
    "\n",
    "    spikes = np.zeros((len(data),m))\n",
    "    neuron_outputs = np.zeros(m)\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        for i in range(m):\n",
    "            mu = min_input + (2*(i + 1)-3)/2*(max_input - min_input)/(m-2)\n",
    "            sigma = (max_input - min_input)/(m-2)\n",
    "            neuron_outputs[i] = norm.pdf(data[j], mu, sigma)\n",
    "\n",
    "        spikes[j,np.argmax(neuron_outputs)] = 1\n",
    "    return spikes\n",
    "\n",
    "def one_hot_place_spike_encoder(data, m, min_input, max_input):\n",
    "    # Simple population coding algorithm adapted from Stagsted et al. (2020) that represents inputs by a location. \n",
    "    # An input is assigned to the neuron that is closest to its value. \n",
    "    # Only one neuron fires at every timestep\n",
    "\n",
    "    if np.isscalar(data):\n",
    "        data = [data]\n",
    "\n",
    "    spikes = np.zeros((len(data),m))\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        size_change = 1/2*(max_input - min_input)/(m-2) # to make sure it has the same lower/upper bounds as the Bohte paper\n",
    "        idx = int(np.round(((data[j] - (min_input - size_change)) / ((max_input + size_change) - (min_input - size_change))) * (m - 1)))\n",
    "        spikes[j, idx] = 1\n",
    "    \n",
    "    return spikes\n",
    "\n",
    "\n",
    "def grf_spike_with_internal_timesteps_encoder(data, min_input, max_input, neurons=10, timesteps=10, beta=1.5):\n",
    "    \"\"\"Create a series of spikes based on Gaussian Receptive Fields\n",
    "    Adapted from algorithm provided in:\n",
    "        Bohté et al. (2002)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    data -- \n",
    "    neurons -- numbers of neurons (default 10)\n",
    "    timesteps -- number of timesteps (default 10)\n",
    "    min_input -- minimal value\n",
    "    max_input -- maximum value\n",
    "    beta -- tuning parameter that determines the width of the receptive fields\n",
    "    \"\"\"\n",
    "\n",
    "    if np.isscalar(data):\n",
    "        data = [data]\n",
    "        \n",
    "    spikes = np.zeros((len(data), timesteps, neurons))\n",
    "    responses = np.zeros(neurons)\n",
    "\n",
    "    # Calculation of mu and sigma of the Gaussian receptive fields\n",
    "    mu = min_input + (2*(np.arange(neurons)+1)-3)/2*(max_input - min_input)/(neurons-2)\n",
    "    sigma = 1/beta*(max_input - min_input)/(neurons-2)\n",
    "    max_prob = norm.pdf(mu[0], mu[0], sigma)\n",
    "\n",
    "    for j in range(len(data)):\n",
    "        for i in range(neurons):\n",
    "            responses[i] = norm.pdf(data[j], mu[i], sigma)\n",
    "            size_change = max_prob / (2 * timesteps)\n",
    "            new = int(np.round(((responses[i] + size_change) / (max_prob + 2 * size_change) * (timesteps + 1)) + 0.0001)) # 0.0001 for roundoff errors...\n",
    "            spiking_time = timesteps - new\n",
    "            if spiking_time < timesteps - 1:\n",
    "                spikes[j, spiking_time, i] = 1\n",
    "    spikes = spikes.reshape([len(data) * timesteps, neurons])\n",
    "    return spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_contrast_decoder(spikes, threshold):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Sengupta et al. (2017)\n",
    "    #   Petro et al. (2020)\n",
    "    signal = np.zeros(len(spikes))\n",
    "    for i in range(1, len(spikes)):\n",
    "        if spikes[i] > 0:\n",
    "            signal[i] = signal[i-1] + threshold\n",
    "        elif spikes[i] < 0:\n",
    "            signal[i] = signal[i-1] - threshold\n",
    "        else:\n",
    "            signal[i] = signal[i-1]\n",
    "    return signal\n",
    "\n",
    "def step_forward_decoder(spikes, threshold, startpoint):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Petro et al. (2020)\n",
    "    signal = np.zeros(len(spikes))\n",
    "    signal[0] = startpoint\n",
    "    for i in range(1,len(spikes)):\n",
    "        if spikes[i] > 0:\n",
    "            signal[i] = signal[i-1] + threshold\n",
    "        elif spikes[i] < 0:\n",
    "            signal[i] = signal[i-1] -threshold\n",
    "        else:\n",
    "            signal[i] = signal[i-1]\n",
    "    return signal\n",
    "\n",
    "def moving_window_decoder(spikes, threshold, startpoint):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Petro et al. (2020)\n",
    "    signal = np.zeros(len(spikes))\n",
    "    signal[0] = startpoint\n",
    "    for i in range(1,len(spikes)):\n",
    "        if spikes[i] > 0:\n",
    "            signal[i] = signal[i-1] + threshold\n",
    "        elif spikes[i] < 0:\n",
    "            signal[i] = signal[i-1] - threshold\n",
    "        else:\n",
    "            signal[i] = signal[i-1]\n",
    "    return signal\n",
    "\n",
    "def ben_spike_decoder(spikes, fir, shift):\n",
    "    # Based on algorithm provided in:\n",
    "    #   Petro et al. (2020)\n",
    "    #   Sengupta et al. (2017)\n",
    "    #   Schrauwen et al. (2003)\n",
    "    signal = np.convolve(spikes, fir)\n",
    "    signal = signal + shift*np.ones(len(signal))\n",
    "    signal = signal[0:(len(signal)-len(fir)+1)]\n",
    "    return signal\n",
    "\n",
    "def grf_spike_decoder(spikes, min_input, max_input):\n",
    "    shape = spikes.shape\n",
    "    signal = np.zeros(shape[0])\n",
    "    for i in range(shape[0]):\n",
    "        signal[i] = min_input + (2*(np.argmax(spikes[i,:]) + 1)-3)/2*(max_input - min_input)/(shape[1]-2)\n",
    "    return signal\n",
    "\n",
    "def one_hot_place_spike_decoder(spikes, min_input, max_input):\n",
    "    shape = spikes.shape\n",
    "    signal = np.zeros(shape[0])\n",
    "    for i in range(shape[0]):\n",
    "        signal[i] = min_input + (2*(np.argmax(spikes[i,:]) + 1)-3)/2*(max_input - min_input)/(shape[1]-2)\n",
    "    return signal\n",
    "\n",
    "def grf_spike_with_internal_timesteps_decoder(spikes, n_timesteps, min_input, max_input):\n",
    "    shape = spikes.shape\n",
    "    spikes = spikes.reshape((int(shape[0]/n_timesteps), n_timesteps, shape[1]))\n",
    "    signal = np.zeros(len(spikes))\n",
    "    mu = np.zeros(shape[1])\n",
    "\n",
    "    for i in range(shape[1]):\n",
    "        mu[i] = min_input + (2*(i + 1)-3)/2*(max_input - min_input)/(shape[1]-2)\n",
    "\n",
    "    for i in range(len(spikes)):\n",
    "        spike_times = np.zeros(shape[1])\n",
    "        for j in range(n_timesteps):\n",
    "            for spike_idx in spikes[i, j, :].nonzero():\n",
    "                spike_times[spike_idx] = n_timesteps - j\n",
    "\n",
    "        weight_center  = np.sum(mu*spike_times)/np.sum(spike_times)\n",
    "        signal[i] = weight_center\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (400,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-791c4d9cff1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msignal\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0msum_of_sine_waves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msignal_guassian\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0msum_of_gaussian_wave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msignal_guassian_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy_gaussian_wave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msignal_noisy\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mnoisy_sine_wave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-e943325b9373>\u001b[0m in \u001b[0;36mnoisy_gaussian_wave\u001b[0;34m(a, m, s, sigma, time)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnoisy_gaussian_wave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepevent/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1758\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \u001b[0mdtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1761\u001b[0m         \u001b[0mcond0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0mcond1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (400,) (2,) "
     ]
    }
   ],
   "source": [
    "dt = 0.01\n",
    "T_max = 4\n",
    "\n",
    "tbr_factors   = [1.005, 1.005, 1.005]\n",
    "sf_thresholds = [0.35, 0.05, 0.35]\n",
    "mw_thresholds = [0.325, 0.015, 0.225]\n",
    "mw_window     = [3, 3, 3]\n",
    "\n",
    "time                  = np.arange(0, T_max, dt)\n",
    "signal                = sum_of_sine_waves([2, -0.5, 0.75], [1.0, 3.0, 5.0], [0.0, 0.0, 0.0], 0.0, time)\n",
    "signal_guassian       = sum_of_gaussian_wave([1, 0.5], [0.2, 0.75], [0.1, 0.1], 0.1, time)\n",
    "signal_guassian_noisy = noisy_gaussian_wave([1, 0.5], [0.2, 0.75], [0.1, 0.1], 0.1, time)\n",
    "signal_noisy          = noisy_sine_wave([1, 0.5], [0.2, 0.75], [0.1, 0.1], 0.1, time)\n",
    "\n",
    "(spikes, threshold) = temporal_contrast_encoder(signal, tbr_factors[0])\n",
    "signal_TBR = temporal_contrast_decoder(spikes, threshold)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1,figsize=(15, 7))\n",
    "axs[0].plot(time, signal)\n",
    "axs[0].plot(time, signal_TBR)\n",
    "axs[0].legend(['Original','Reconstructed'])\n",
    "axs[0].set_ylabel('voltage(V)')\n",
    "axs[0].set_title(\"Temporal Contrast Algorithm TBR\")\n",
    "axs[1].stem(time,spikes,use_line_collection=True)\n",
    "axs[1].set_ylabel('Spikes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2c137e3224f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mspikes_TBR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemporal_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbr_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0msignal_TBR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtemporal_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes_TBR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "dt = 0.01\n",
    "T_max = 4\n",
    "time = np.arange(0, T_max, dt)\n",
    "\n",
    "S = list()\n",
    "S.append(sum_of_sine_waves([2, -0.5, 0.75], [1.0, 3.0, 5.0], [0.0, 0.0, 0.0], 0.0, time))\n",
    "S.append(sum_of_sine_waves([-0.25], [1.0], [0.0], 0.05, time))\n",
    "S.append(sum_of_gaussian_wave([1, 0.5], [0.2, 0.75], [0.1, 0.1], 0.1, time))\n",
    "\n",
    "tbr_factors = [1.005, 1.005, 1.005]\n",
    "    \n",
    "sf_thresholds = [0.35, 0.05, 0.35]\n",
    "    \n",
    "mw_thresholds = [0.325, 0.015, 0.225]\n",
    "mw_window = [3, 3, 3]\n",
    "\n",
    "for i in range(len(S)):\n",
    "\n",
    "    (spikes_TBR, threshold) = temporal_contrast(S[i], tbr_factors[i])\n",
    "    signal_TBR = 2*temporal_contrast(spikes_TBR, threshold)\n",
    "\n",
    "    spikes_SF, startpoint = step_forward(S[i], sf_thresholds[i])\n",
    "    signal_SF = DS.step_forward(spikes_SF, sf_thresholds[i], startpoint)\n",
    "\n",
    "    spikes_MW, startpoint = moving_window(S[i], mw_thresholds[i], mw_window[i])\n",
    "    signal_MW = DS.moving_window(spikes_MW, mw_thresholds[i], startpoint)\n",
    "\n",
    "    plt.subplot(3*len(S),3,(1+i*3*len(S),4+i*3*len(S)))\n",
    "    plt.plot(time, S[i])\n",
    "    plt.plot(time, signal_TBR)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    if i == 0:\n",
    "        plt.title(\"Temporal Contrast Algorithm TBR\")\n",
    "\n",
    "        plt.subplot(3*len(S),3,7+i*3*len(S))\n",
    "        plt.stem(time, spikes_TBR)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.subplot(3*len(S),3,(2+i*3*len(S),5+i*3*len(S)))\n",
    "        plt.plot(time, S[i])\n",
    "        plt.plot(time, signal_SF)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        if i == 0:\n",
    "            plt.title(\"Step Forward Algorithm SF\")\n",
    "\n",
    "        plt.subplot(3*len(S),3,8+i*3*len(S))\n",
    "        plt.stem(time, spikes_SF)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.subplot(3*len(S),3,(3+i*3*len(S),6+i*3*len(S)))\n",
    "        plt.plot(time, S[i])\n",
    "        plt.plot(time, signal_MW)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        if i == 0:\n",
    "            plt.title(\"Moving Window Algorithm MW\")\n",
    "\n",
    "        plt.subplot(3*len(S),3,9+i*3*len(S))\n",
    "        plt.stem(time, spikes_MW)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    hsa_window = [12, 15, 12]\n",
    "    hsa_fir = list()\n",
    "    hsa_fir.append(signal.triang(hsa_window[0]))\n",
    "    hsa_fir.append(norm.pdf(np.linspace(1, hsa_window[1], hsa_window[1]), 0, 5))\n",
    "    hsa_fir.append(signal.triang(hsa_window[2]))\n",
    "\n",
    "    hsa_m_thresholds = [0.85, 0.05, 0.5]\n",
    "\n",
    "    bsa_window = [9, 10, 8]\n",
    "    bsa_fir = list()\n",
    "    bsa_fir.append(signal.triang(bsa_window[0]))\n",
    "    bsa_fir.append(norm.pdf(np.linspace(1, bsa_window[1], bsa_window[1]), 1.5, 3.5))\n",
    "    bsa_fir.append(signal.triang(bsa_window[2]))\n",
    "\n",
    "    bsa_thresholds = [1.175, 1.05, 1.2]\n",
    "\n",
    "    for i in range(len(S)):\n",
    "\n",
    "        spikes_HSA, shift = ES.hough_spike(S[i], hsa_fir[i])\n",
    "        signal_HSA = DS.ben_spike(spikes_HSA, hsa_fir[i], shift)\n",
    "\n",
    "        spikes_HSAm, shift = ES.modified_hough_spike(S[i], hsa_fir[i], hsa_m_thresholds[i])\n",
    "        signal_HSAm = DS.ben_spike(spikes_HSAm, hsa_fir[i], shift)\n",
    "\n",
    "        spikes_BSA, shift = ES.ben_spike(S[i], bsa_fir[i], bsa_thresholds[i])\n",
    "        signal_BSA = DS.ben_spike(spikes_BSA, bsa_fir[i], shift)\n",
    "\n",
    "        plt.subplot(3*len(S),3,(1+i*3*len(S),4+i*3*len(S)))\n",
    "        plt.plot(time, S[i])\n",
    "        plt.plot(time, signal_HSA)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        if i == 0:\n",
    "            plt.title(\"Hough Spike Algorithm HSA\")\n",
    "\n",
    "        plt.subplot(3*len(S),3,7+i*3*len(S))\n",
    "        plt.stem(time, spikes_HSA)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.subplot(3*len(S),3,(2+i*3*len(S),5+i*3*len(S)))\n",
    "        plt.plot(time, S[i])\n",
    "        plt.plot(time, signal_HSAm)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        if i == 0:\n",
    "            plt.title(\"Threshold Hough Spike Algorithm T-HSA\")\n",
    "\n",
    "        plt.subplot(3*len(S),3,8+i*3*len(S))\n",
    "        plt.stem(time, spikes_HSAm)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.subplot(3*len(S),3,(3+i*3*len(S),6+i*3*len(S)))\n",
    "        plt.plot(time, S[i])\n",
    "        plt.plot(time, signal_BSA)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        if i == 0:\n",
    "            plt.title(\"Ben Spike Algorithm BSA\")\n",
    "\n",
    "        plt.subplot(3*len(S),3,9+i*3*len(S))\n",
    "        plt.stem(time, spikes_BSA)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
